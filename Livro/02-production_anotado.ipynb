{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"jupytext":{"split_at_heading":true},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#hide\n! [ -e /content ] && pip install -Uqq fastbook\nimport fastbook\nfastbook.setup_book()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T13:27:13.491290Z","iopub.execute_input":"2025-06-18T13:27:13.491536Z","iopub.status.idle":"2025-06-18T13:29:01.191584Z","shell.execute_reply.started":"2025-06-18T13:27:13.491515Z","shell.execute_reply":"2025-06-18T13:29:01.190551Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m719.8/719.8 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.1/124.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m246.9/246.9 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"#hide\nfrom fastbook import *\nfrom fastai.vision.widgets import *","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T13:38:55.004293Z","iopub.execute_input":"2025-06-18T13:38:55.007045Z","iopub.status.idle":"2025-06-18T13:38:55.038934Z","shell.execute_reply.started":"2025-06-18T13:38:55.006956Z","shell.execute_reply":"2025-06-18T13:38:55.038018Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"# From Model to Production","metadata":{}},{"cell_type":"markdown","source":"## The Practice of Deep Learning","metadata":{}},{"cell_type":"markdown","source":"### Starting Your Project","metadata":{}},{"cell_type":"markdown","source":"### The State of Deep Learning","metadata":{}},{"cell_type":"markdown","source":"#### Computer vision","metadata":{}},{"cell_type":"markdown","source":"#### Text (natural language processing)","metadata":{}},{"cell_type":"markdown","source":"#### Combining text and images","metadata":{}},{"cell_type":"markdown","source":"#### Tabular data","metadata":{}},{"cell_type":"markdown","source":"#### Recommendation systems","metadata":{}},{"cell_type":"markdown","source":"#### Other data types","metadata":{}},{"cell_type":"markdown","source":"### The Drivetrain Approach","metadata":{}},{"cell_type":"markdown","source":"## Gathering Data","metadata":{}},{"cell_type":"markdown","source":"# clean\nTo download images with Bing Image Search, sign up at [Microsoft Azure](https://azure.microsoft.com/en-us/services/cognitive-services/bing-web-search-api/) for a free account. You will be given a key, which you can copy and enter in a cell as follows (replacing 'XXX' with your key and executing it):","metadata":{}},{"cell_type":"code","source":"key = os.environ.get('AZURE_SEARCH_KEY', 'XXX')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T13:40:24.443944Z","iopub.execute_input":"2025-06-18T13:40:24.445045Z","iopub.status.idle":"2025-06-18T13:40:24.451787Z","shell.execute_reply.started":"2025-06-18T13:40:24.445005Z","shell.execute_reply":"2025-06-18T13:40:24.450688Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"search_images_bing","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T13:40:25.742108Z","iopub.execute_input":"2025-06-18T13:40:25.742462Z","iopub.status.idle":"2025-06-18T13:40:25.751875Z","shell.execute_reply.started":"2025-06-18T13:40:25.742437Z","shell.execute_reply":"2025-06-18T13:40:25.750738Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"<function fastbook.search_images_bing(key, term, min_sz=128, max_images=150)>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"results = search_images_bing(key, 'grizzly bear')\nims = results.attrgot('contentUrl')\nlen(ims)\n\n# search_images_bing(key, 'grizzly bear'): busca de imagens no Bing, usando a API, com autenticação via key e o termo de busca 'grizzly bear'.\n# results =: Vai receber os resultados da busca, geralmente como uma lista de objetos (JSON-like) contendo URLs, metadados, outros detalhes.\n# ims = results.attrgot('contentUrl')\n# .attrgot('contentUrl'): Extrai só os URLs diretos das imagens.","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T13:40:27.656994Z","iopub.execute_input":"2025-06-18T13:40:27.658037Z","iopub.status.idle":"2025-06-18T13:40:27.915666Z","shell.execute_reply.started":"2025-06-18T13:40:27.658000Z","shell.execute_reply":"2025-06-18T13:40:27.914454Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/2348086299.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch_images_bing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'grizzly bear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrgot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'contentUrl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/fastbook/__init__.py\u001b[0m in \u001b[0;36msearch_images_bing\u001b[0;34m(key, term, min_sz, max_images)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0msearch_url\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://api.bing.microsoft.com/v7.0/images/search\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"Ocp-Apim-Subscription-Key\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: PermissionDenied for url: https://api.bing.microsoft.com/v7.0/images/search?q=grizzly+bear&count=150&min_height=128&min_width=128"],"ename":"HTTPError","evalue":"401 Client Error: PermissionDenied for url: https://api.bing.microsoft.com/v7.0/images/search?q=grizzly+bear&count=150&min_height=128&min_width=128","output_type":"error"}],"execution_count":5},{"cell_type":"code","source":"#hide\nims = ['http://3.bp.blogspot.com/-S1scRCkI3vY/UHzV2kucsPI/AAAAAAAAA-k/YQ5UzHEm9Ss/s1600/Grizzly%2BBear%2BWildlife.jpg']\n\n# criando uma lista com apenas uma URL de imagem (nesse caso, de um grizzly bear). Isso é uma forma prática de testar o download antes de baixar várias imagens.\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T13:54:56.039681Z","iopub.execute_input":"2025-06-18T13:54:56.040795Z","iopub.status.idle":"2025-06-18T13:54:56.045765Z","shell.execute_reply.started":"2025-06-18T13:54:56.040756Z","shell.execute_reply":"2025-06-18T13:54:56.044669Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"dest = 'images/grizzly.jpg'\ndownload_url(ims[0], dest)\n\n# dest = 'images/grizzly.jpg': \n#Isso define o caminho e nome do arquivo local onde você vai salvar a imagem. images/ → Uma pasta (lembre-se: ela precisa existir antes, ou o Python pode dar erro). grizzly.jpg → Nome do arquivo que vai ser salvo.\n\n# download_url(ims[0], dest):\n# Acessa a URL da imagem (neste caso, o primeiro item da lista ims, que você definiu manualmente)\n# Faz o download do arquivo\n# Salva o conteúdo no local definido por dest e cria o arquivo grizzly.jpg dentro da pasta images","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"im = Image.open(dest)\nim.to_thumb(128,128)\n\n# Image.open(dest)\n# Abre o arquivo da imagem que você salvou no caminho dest (ou seja: images/grizzly.jpg).\n\n# im.to_thumb(128,128)\n# Cria uma miniatura da imagem com no máximo 128×128 pixels, mantendo a proporção original da imagem.","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"bear_types = 'grizzly','black','teddy'\npath = Path('bears')\n\n# bear_types = 'grizzly','black','teddy': \n# Aqui você está criando uma tupla com os tipos de ursos que vai querer classificar.\n\n# path = Path('bears')\n# Cria um objeto Path (da biblioteca Python pathlib) que aponta para o diretório \"bears\".","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"if not path.exists():\n    path.mkdir()\n    for o in bear_types:\n        dest = (path/o)\n        dest.mkdir(exist_ok=True)\n        results = search_images_bing(key, f'{o} bear')\n        download_images(dest, urls=results.attrgot('contentUrl'))\n\n# if not path.exists(): path.mkdir()\n# Se a pasta bears/ ainda não existir, ele cria.\n\n# for o in bear_types:\n# Pra cada tipo de urso definido antes ('grizzly', 'black', 'teddy'), ele vai fazer o seguinte:\n\n# dest = (path/o) dest.mkdir(exist_ok=True)\n# Isso cria (se ainda não existir) a pasta de cada categoria de urso definida.\n\n# results = search_images_bing(key, f'{o} bear'): Faz uma busca por imagens no Bing para cada tipo de urso\n# download_images(dest, urls=results.attrgot('contentUrl'))\n# Faz o download das imagens, salvando todas dentro da pasta de cada urso.\n# Usa só os URLs das imagens (pegos via results.attrgot('contentUrl')).\n\n# O que você terá ao final:\n# Uma estrutura de pastas assim:\n# bears/\n#    grizzly/\n#        img1.jpg\n#        img2.jpg\n#        ...\n#     black/\n#        ...","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"fns = get_image_files(path)\nfns\n\n# get_image_files(path)\n# Percorre recursivamente a pasta path\n# Procura por arquivos de imagem\n# Retorna uma lista de caminhos (Path objects) para cada imagem encontrada","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T14:10:25.392690Z","iopub.execute_input":"2025-06-18T14:10:25.394126Z","iopub.status.idle":"2025-06-18T14:10:25.436391Z","shell.execute_reply.started":"2025-06-18T14:10:25.394085Z","shell.execute_reply":"2025-06-18T14:10:25.435015Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/1024656337.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_image_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'path' is not defined"],"ename":"NameError","evalue":"name 'path' is not defined","output_type":"error"}],"execution_count":7},{"cell_type":"code","source":"failed = verify_images(fns)\nfailed\n\n# Essa função da FastAI percorre cada arquivo de imagem na lista fns e tenta abrir cada um.\n# Se a imagem abrir corretamente: nada acontece\n# Se imagem corrompida ou inválida: o caminho da imagem é adicionado à lista failed","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"failed.map(Path.unlink);\n\n# failed: É a lista de imagens que falharam na verificação (arquivos corrompidos, quebrados, etc)\n# .map(Path.unlink): Aplica a função Path.unlink() em cada item da lista\n# Path.unlink(): Deleta o arquivo do disco (remove a imagem correspondente)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-18T14:16:11.244701Z","iopub.execute_input":"2025-06-18T14:16:11.245205Z","iopub.status.idle":"2025-06-18T14:16:11.280039Z","shell.execute_reply.started":"2025-06-18T14:16:11.245171Z","shell.execute_reply":"2025-06-18T14:16:11.278643Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/452877257.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfailed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munlink\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'failed' is not defined"],"ename":"NameError","evalue":"name 'failed' is not defined","output_type":"error"}],"execution_count":8},{"cell_type":"markdown","source":"### Sidebar: Getting Help in Jupyter Notebooks","metadata":{}},{"cell_type":"markdown","source":"### End sidebar","metadata":{}},{"cell_type":"markdown","source":"## From Data to DataLoaders","metadata":{}},{"cell_type":"code","source":"bears = DataBlock(\n    blocks=(ImageBlock, CategoryBlock), \n    get_items=get_image_files, \n    splitter=RandomSplitter(valid_pct=0.2, seed=42),\n    get_y=parent_label,\n    item_tfms=Resize(128))\n\n# O que é um DataBlock?\n# É uma fábrica de DataLoaders, onde você define passo a passo como o FastAI deve ler, processar e dividir os dados.\n\n# blocks=(ImageBlock, CategoryBlock)\t\n# Diz que os inputs são imagens e os targets são categorias (classes).\n\n# get_items=get_image_files: \n# Diz ao FastAI como encontrar os arquivos de imagem dentro da pasta base (path).\n \n# splitter=RandomSplitter(valid_pct=0.2, seed=42)\t\n# Faz uma divisão aleatória entre treino e validação. Aqui, 20% das imagens vão pra validação e o resto pro treino. O seed=42 garante reprodutibilidade (sempre a mesma divisão se rodar de novo).\n\n# get_y=parent_label\t\n# Diz como o FastAI vai obter o rótulo (classe) de cada imagem: olhando o nome da subpasta onde a imagem está (ex: grizzly, black, teddy).\n\n# em_tfms=Resize(128)\t\n# Faz um resize de todas as imagens para 128×128 pixels na hora que o item é carregado (transformação no nível de item).","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dls = bears.dataloaders(path)\n\n# Pega a \"receita\" que você criou no DataBlock (chamado bears) e aplica ela no diretório base ","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"dls.valid.show_batch(max_n=4, nrows=1)\n\n# Agora você está visualizando um batch da validação, com controle sobre o número de imagens exibidas e o layout\n\n# dls.valid: Refere-se ao DataLoader de validação, dentro do seu dls (DataLoaders)\n# .show_batch(): Função da FastAI que exibe um batch de imagens junto com seus rótulos\n# max_n=4: Limita a visualização a no máximo 4 imagens\n# nrows=1: Exibe as imagens em uma única linha (uma linha, várias colunas)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"bears = bears.new(item_tfms=Resize(128, ResizeMethod.Squish))\ndls = bears.dataloaders(path)\ndls.valid.show_batch(max_n=4, nrows=1)\n\n# Atualizando o DataBlock para mudar o tipo de redimensionamento de imagem. \n\n# 1. bears.new(item_tfms=Resize(128, ResizeMethod.Squish))\n# Isso cria uma nova cópia do seu DataBlock, com uma alteração específica:\n# Agora, o redimensionamento das imagens vai ser feito com o método squish\n\n# 2. dls = bears.dataloaders(path)\n# Gera novamente os DataLoaders com esse novo DataBlock modificado.\n\n# 3. dls.valid.show_batch(max_n=4, nrows=1)\n# Agora você está visualizando novamente o batch,","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"bears = bears.new(item_tfms=Resize(128, ResizeMethod.Pad, pad_mode='zeros'))\ndls = bears.dataloaders(path)\ndls.valid.show_batch(max_n=4, nrows=1)\n\n# Semelhante ao codigo acima, mas usando o metodo Pad. Ele mantém a proporção original da imagem, e se faltar espaço, o FastAI preenche as bordas com zeros (preto).","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"bears = bears.new(item_tfms=RandomResizedCrop(128, min_scale=0.3))\ndls = bears.dataloaders(path)\ndls.train.show_batch(max_n=4, nrows=1, unique=True)\n\n# Semelhante ao codigo acima, mas usando Random Sized Crop. Ele seleciona aleatoriamente uma parte (um \"crop\") da imagem original. A área selecionada pode ter um tamanho mínimo em relação ao original.","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Data Augmentation","metadata":{}},{"cell_type":"code","source":"bears = bears.new(item_tfms=Resize(128), batch_tfms=aug_transforms(mult=2))\ndls = bears.dataloaders(path)\ndls.train.show_batch(max_n=8, nrows=2, unique=True)\n\n# Agora você está aplicando data augmentation no nível de batch, com várias transformações aleatórias (como flips, rotações, mudanças de contraste, etc).\n\n# Diferença entre item_tfms e batch_tfms\n# item_tfms: Logo que cada item (imagem) é carregado\n# batch_tfms: Depois que o batch é montado (várias imagens juntas)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Training Your Model, and Using It to Clean Your Data","metadata":{}},{"cell_type":"code","source":"bears = bears.new(\n    item_tfms=RandomResizedCrop(224, min_scale=0.5),\n    batch_tfms=aug_transforms())\ndls = bears.dataloaders(path)\n\n# Criando novo dataloaders com: \n# Imagens redimensionadas 224x224\n# Crop aleatório\n# Data augmentation por batch","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"learn = vision_learner(dls, resnet18, metrics=error_rate)\nlearn.fine_tune(4)\n\n# Criando um Learner com uma ResNet-18 e começando o treinamento com fine-tuning.\n# vision_learner: Uma função da FastAI que cria um Learner já pré-configurado para visão computacional\n# dls: Seus DataLoaders (treino + validação)\n# resnet18: O modelo que será usado → ResNet-18, uma CNN bastante usada para classificação de imagens\n# metrics=error_rate: Pede ao FastAI para acompanhar a taxa de erro (1 - acurácia) durante o treino\n\n# learn.fine_tune(4)\n# Fase 1: Treina só a última camada (head) por 1 época (pra adaptar rapidamente ao novo dataset)\n# Fase 2: Desbloqueia as camadas da ResNet e faz o fine-tuning de toda a rede por mais 3 épocas","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"interp = ClassificationInterpretation.from_learner(learn)\ninterp.plot_confusion_matrix()\n\n# Criando matriz de confusao","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"interp.plot_top_losses(5, nrows=1)\n\n# Mostrando imagens com maior loss","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"cleaner = ImageClassifierCleaner(learn)\ncleaner\n\n# Ferramenta do FastAI que permite ver as imagens com maior loss de forma interativa","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#hide\n# for idx in cleaner.delete(): cleaner.fns[idx].unlink()\n# for idx,cat in cleaner.change(): shutil.move(str(cleaner.fns[idx]), path/cat)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## Turning Your Model into an Online Application","metadata":{}},{"cell_type":"markdown","source":"### Using the Model for Inference","metadata":{}},{"cell_type":"code","source":"learn.export()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"path = Path()\npath.ls(file_exts='.pkl')","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"learn_inf = load_learner(path/'export.pkl')","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"learn_inf.predict('images/grizzly.jpg')","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"learn_inf.dls.vocab","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Creating a Notebook App from the Model","metadata":{}},{"cell_type":"code","source":"btn_upload = widgets.FileUpload()\nbtn_upload","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#hide\n# For the book, we can't actually click an upload button, so we fake it\nbtn_upload = SimpleNamespace(data = ['images/grizzly.jpg'])","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"img = PILImage.create(btn_upload.data[-1])","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"out_pl = widgets.Output()\nout_pl.clear_output()\nwith out_pl: display(img.to_thumb(128,128))\nout_pl","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pred,pred_idx,probs = learn_inf.predict(img)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lbl_pred = widgets.Label()\nlbl_pred.value = f'Prediction: {pred}; Probability: {probs[pred_idx]:.04f}'\nlbl_pred","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"btn_run = widgets.Button(description='Classify')\nbtn_run","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def on_click_classify(change):\n    img = PILImage.create(btn_upload.data[-1])\n    out_pl.clear_output()\n    with out_pl: display(img.to_thumb(128,128))\n    pred,pred_idx,probs = learn_inf.predict(img)\n    lbl_pred.value = f'Prediction: {pred}; Probability: {probs[pred_idx]:.04f}'\n\nbtn_run.on_click(on_click_classify)","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#hide\n#Putting back btn_upload to a widget for next cell\nbtn_upload = widgets.FileUpload()","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"code","source":"VBox([widgets.Label('Select your bear!'), \n      btn_upload, btn_run, out_pl, lbl_pred])","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Turning Your Notebook into a Real App","metadata":{}},{"cell_type":"code","source":"#hide\n# !pip install voila\n# !jupyter serverextension enable --sys-prefix voila ","metadata":{},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Deploying your app","metadata":{}},{"cell_type":"markdown","source":"## How to Avoid Disaster","metadata":{}},{"cell_type":"markdown","source":"### Unforeseen Consequences and Feedback Loops","metadata":{}},{"cell_type":"markdown","source":"## Get Writing!","metadata":{}},{"cell_type":"markdown","source":"## Questionnaire","metadata":{}},{"cell_type":"markdown","source":"1. Provide an example of where the bear classification model might work poorly in production, due to structural or style differences in the training data.\n1. Where do text models currently have a major deficiency?\n1. What are possible negative societal implications of text generation models?\n1. In situations where a model might make mistakes, and those mistakes could be harmful, what is a good alternative to automating a process?\n1. What kind of tabular data is deep learning particularly good at?\n1. What's a key downside of directly using a deep learning model for recommendation systems?\n1. What are the steps of the Drivetrain Approach?\n1. How do the steps of the Drivetrain Approach map to a recommendation system?\n1. Create an image recognition model using data you curate, and deploy it on the web.\n1. What is `DataLoaders`?\n1. What four things do we need to tell fastai to create `DataLoaders`?\n1. What does the `splitter` parameter to `DataBlock` do?\n1. How do we ensure a random split always gives the same validation set?\n1. What letters are often used to signify the independent and dependent variables?\n1. What's the difference between the crop, pad, and squish resize approaches? When might you choose one over the others?\n1. What is data augmentation? Why is it needed?\n1. What is the difference between `item_tfms` and `batch_tfms`?\n1. What is a confusion matrix?\n1. What does `export` save?\n1. What is it called when we use a model for getting predictions, instead of training?\n1. What are IPython widgets?\n1. When might you want to use CPU for deployment? When might GPU be better?\n1. What are the downsides of deploying your app to a server, instead of to a client (or edge) device such as a phone or PC?\n1. What are three examples of problems that could occur when rolling out a bear warning system in practice?\n1. What is \"out-of-domain data\"?\n1. What is \"domain shift\"?\n1. What are the three steps in the deployment process?","metadata":{}},{"cell_type":"markdown","source":"### Further Research","metadata":{}},{"cell_type":"markdown","source":"1. Consider how the Drivetrain Approach maps to a project or problem you're interested in.\n1. When might it be best to avoid certain types of data augmentation?\n1. For a project you're interested in applying deep learning to, consider the thought experiment \"What would happen if it went really, really well?\"\n1. Start a blog, and write your first blog post. For instance, write about what you think deep learning might be useful for in a domain you're interested in.","metadata":{}},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}